# Comparing `tmp/pp_project_pkg-1.0.202307040935-py3-none-any.whl.zip` & `tmp/pp_project_pkg-1.0.202307041256-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,22 +1,22 @@
-Zip file size: 14033 bytes, number of entries: 20
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-27 22:23 mlflow_pipelines/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-27 22:23 mlflow_pipelines/fetch_data/__init__.py
--rw-rw-r--  2.0 unx      887 b- defN 23-Jun-27 22:23 mlflow_pipelines/fetch_data/get_data.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-27 22:23 mlflow_pipelines/train_model/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-27 22:23 mlflow_pipelines/train_model/model_train.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-27 22:23 mlflow_pipelines/upload_data/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Jun-27 22:23 mlflow_pipelines/upload_data/data_upload.py
--rw-rw-r--  2.0 unx       71 b- defN 23-Jun-07 11:24 pp_project_pkg/__init__.py
--rw-rw-r--  2.0 unx     4341 b- defN 23-Jul-03 02:36 pp_project_pkg/extra.py
--rw-rw-r--  2.0 unx     5335 b- defN 23-Jun-23 12:39 pp_project_pkg/linear_train.py
--rw-rw-r--  2.0 unx      577 b- defN 23-Jun-07 11:24 pp_project_pkg/newsvendor.py
--rw-rw-r--  2.0 unx     9252 b- defN 23-Jun-27 22:23 pp_project_pkg/pp_tables.py
--rw-rw-r--  2.0 unx     7448 b- defN 23-Jul-01 19:37 pp_project_pkg/utils.py
--rw-rw-r--  2.0 unx      396 b- defN 23-Jul-04 09:35 pp_project_pkg/version.py
--rw-rw-r--  2.0 unx     5301 b- defN 23-Jul-02 01:31 pp_project_pkg/wrangling.py
--rwxrwxr-x  2.0 unx     1316 b- defN 23-Jun-07 11:24 pp_project_pkg-1.0.202307040935.data/scripts/pp_project_run.py
--rw-rw-r--  2.0 unx      191 b- defN 23-Jul-04 09:35 pp_project_pkg-1.0.202307040935.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Jul-04 09:35 pp_project_pkg-1.0.202307040935.dist-info/WHEEL
--rw-rw-r--  2.0 unx       32 b- defN 23-Jul-04 09:35 pp_project_pkg-1.0.202307040935.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     1801 b- defN 23-Jul-04 09:35 pp_project_pkg-1.0.202307040935.dist-info/RECORD
-20 files, 37040 bytes uncompressed, 11005 bytes compressed:  70.3%
+Zip file size: 14436 bytes, number of entries: 20
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jun-27 10:35 mlflow_pipelines/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jun-27 10:35 mlflow_pipelines/fetch_data/__init__.py
+-rw-rw-r--  2.0 unx      887 b- defN 23-Jun-27 14:49 mlflow_pipelines/fetch_data/get_data.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jun-27 10:35 mlflow_pipelines/train_model/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jun-27 10:34 mlflow_pipelines/train_model/model_train.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jun-27 10:35 mlflow_pipelines/upload_data/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jun-27 10:34 mlflow_pipelines/upload_data/data_upload.py
+-rw-rw-r--  2.0 unx       71 b- defN 23-Jun-06 14:15 pp_project_pkg/__init__.py
+-rw-rw-r--  2.0 unx     4343 b- defN 23-Jul-04 12:51 pp_project_pkg/extra.py
+-rw-rw-r--  2.0 unx      577 b- defN 23-Jun-06 14:14 pp_project_pkg/newsvendor.py
+-rw-rw-r--  2.0 unx     9252 b- defN 23-Jun-27 13:59 pp_project_pkg/pp_tables.py
+-rw-rw-r--  2.0 unx     7612 b- defN 23-Jul-04 12:55 pp_project_pkg/train_loop.py
+-rw-rw-r--  2.0 unx     7448 b- defN 23-Jul-04 10:39 pp_project_pkg/utils.py
+-rw-rw-r--  2.0 unx      396 b- defN 23-Jul-04 12:56 pp_project_pkg/version.py
+-rw-rw-r--  2.0 unx     5301 b- defN 23-Jul-04 10:39 pp_project_pkg/wrangling.py
+-rwxrwxr-x  2.0 unx     1316 b- defN 23-Jun-06 15:48 pp_project_pkg-1.0.202307041256.data/scripts/pp_project_run.py
+-rw-rw-r--  2.0 unx      191 b- defN 23-Jul-04 12:56 pp_project_pkg-1.0.202307041256.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-Jul-04 12:56 pp_project_pkg-1.0.202307041256.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       32 b- defN 23-Jul-04 12:56 pp_project_pkg-1.0.202307041256.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     1799 b- defN 23-Jul-04 12:56 pp_project_pkg-1.0.202307041256.dist-info/RECORD
+20 files, 39317 bytes uncompressed, 11412 bytes compressed:  71.0%
```

## zipnote {}

```diff
@@ -21,41 +21,41 @@
 
 Filename: pp_project_pkg/__init__.py
 Comment: 
 
 Filename: pp_project_pkg/extra.py
 Comment: 
 
-Filename: pp_project_pkg/linear_train.py
-Comment: 
-
 Filename: pp_project_pkg/newsvendor.py
 Comment: 
 
 Filename: pp_project_pkg/pp_tables.py
 Comment: 
 
+Filename: pp_project_pkg/train_loop.py
+Comment: 
+
 Filename: pp_project_pkg/utils.py
 Comment: 
 
 Filename: pp_project_pkg/version.py
 Comment: 
 
 Filename: pp_project_pkg/wrangling.py
 Comment: 
 
-Filename: pp_project_pkg-1.0.202307040935.data/scripts/pp_project_run.py
+Filename: pp_project_pkg-1.0.202307041256.data/scripts/pp_project_run.py
 Comment: 
 
-Filename: pp_project_pkg-1.0.202307040935.dist-info/METADATA
+Filename: pp_project_pkg-1.0.202307041256.dist-info/METADATA
 Comment: 
 
-Filename: pp_project_pkg-1.0.202307040935.dist-info/WHEEL
+Filename: pp_project_pkg-1.0.202307041256.dist-info/WHEEL
 Comment: 
 
-Filename: pp_project_pkg-1.0.202307040935.dist-info/top_level.txt
+Filename: pp_project_pkg-1.0.202307041256.dist-info/top_level.txt
 Comment: 
 
-Filename: pp_project_pkg-1.0.202307040935.dist-info/RECORD
+Filename: pp_project_pkg-1.0.202307041256.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## pp_project_pkg/extra.py

```diff
@@ -98,8 +98,9 @@
                                                        matching_rows[i]['no_of_covers']])
             
     columns = ['actual_production','rework_or_reuse','actual_consumption','waste','actual_covers','no_of_covers']
     asd = list(dict_to_train.keys())
     for i in range(len(asd)):
         dict_to_train[asd[i]] = pd.DataFrame(dict_to_train[asd[i]], columns=columns)
 
-    return dict_to_train
+    return dict_to_train
+
```

## pp_project_pkg/version.py

```diff
@@ -1,11 +1,11 @@
 VERSION_YEAR = 2023
 VERSION_MONTH = int('07')
 VERSION_DAY = int('04')
-VERSION_HOUR = int('09')
-VERSION_MINUTE = int('35')
+VERSION_HOUR = int('12')
+VERSION_MINUTE = int('56')
 MAJOR_VERSION = 1
 MINOR_VERSION = 0
-PATCH_VERSION = 202307040935
-version_date = '2023/07/04 09:35'
+PATCH_VERSION = 202307041256
+version_date = '2023/07/04 12:56'
 version = '{}.{}.{}'.format(MAJOR_VERSION, MINOR_VERSION, PATCH_VERSION)
 __all__  = ['MAJOR_VERSION', 'MINOR_VERSION', 'PATCH_VERSION', 'version_date', 'version']
```

## Comparing `pp_project_pkg/linear_train.py` & `pp_project_pkg/train_loop.py`

 * *Files 26% similar despite different names*

```diff
@@ -9,14 +9,80 @@
 from sklearn.compose import ColumnTransformer
 from sklearn.pipeline import Pipeline
 from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
 from sklearn.ensemble import RandomForestRegressor
 import matplotlib.pyplot as plt
 
 
+def linear_train(data,input_cols=['actual_covers'],output_cols=['actual_production'],test_case=[130],logger=None):
+    """
+    Linear train a model on the data with input_cols and output_cols
+    Args:
+        data : pd.DataFrame
+        input_cols : list of input columns
+        output_cols : list of output columns
+    Returns:
+        model : sklearn model object
+    """
+    from sklearn.linear_model import LinearRegression
+
+    # create the input and output variables for the model
+    
+    if logger:
+        logger.info("Training linear model")
+        logger.info("Input columns : {}".format(input_cols))
+        logger.info("Output columns : {}".format(output_cols))
+    X = data[input_cols].tolist()
+    y = data[output_cols].tolist()
+
+    if logger:
+        logger.info("training on events : {}".format(len(X)))
+    # convert the lists to numpy arrays
+    dp1 = np.array(X)
+    dp1 = np.reshape(dp1,[len(X),1])
+
+    dp2 = np.array(y)
+    dp2 = np.reshape(dp2,[len(y),1])
+
+    # Splitting data into training and test sets (keeping the latest 10% for evaluation)
+    train_size = int(0.9 * len(dp1))
+    X_train, X_test = dp1[:train_size], dp1[train_size:]
+    y_train, y_test = dp2[:train_size], dp2[train_size:]
+
+
+    # create a linear regression model and fit it to the data
+    model = LinearRegression()
+    model.fit(X_train, y_train)
+
+    # Predicting and evaluating
+    y_pred = model.predict(X_test)
+    mse = mean_squared_error(y_test, y_pred)
+    mae = mean_absolute_error(y_test, y_pred) 
+    r2 = r2_score(y_test, y_pred)
+
+    if logger:
+        logger.info('Mean squared error: {}'.format(mse))
+        logger.info('Mean absolute error: {}'.format(mae))
+        logger.info('R2 score: {}'.format(r2))   
+
+    # Check feature importances
+    importances = model.feature_importances_ 
+    feature_df = pd.DataFrame({'Feature': list(X), 'Importance': importances})
+    feature_df = feature_df.sort_values('Importance', ascending=False)
+
+    # perform inference to predict actual_production based on no_of_covers
+    if test_case:
+        input_data = [test_case]
+        predicted_output = model.predict(input_data)
+        if logger:
+            logger.info("Predicted output for a test case: {}".format(predicted_output))
+    return model,feature_df
+
+
+
 def train_model(data,logger=None):
     """
     Trains a linear model on the data and upload the model to the cloud with parameters
     
     Args:
         data: pd.DataFrame
         logger: logger object
```

## Comparing `pp_project_pkg-1.0.202307040935.data/scripts/pp_project_run.py` & `pp_project_pkg-1.0.202307041256.data/scripts/pp_project_run.py`

 * *Files identical despite different names*

## Comparing `pp_project_pkg-1.0.202307040935.dist-info/RECORD` & `pp_project_pkg-1.0.202307041256.dist-info/RECORD`

 * *Files 17% similar despite different names*

```diff
@@ -2,19 +2,19 @@
 mlflow_pipelines/fetch_data/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow_pipelines/fetch_data/get_data.py,sha256=OCoL8C6L0H-tKN5p5eSxo6l6elnrXU21EPB5Tk-IgY8,887
 mlflow_pipelines/train_model/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow_pipelines/train_model/model_train.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow_pipelines/upload_data/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow_pipelines/upload_data/data_upload.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pp_project_pkg/__init__.py,sha256=9idX2X6SQKZg--ziGy6Ii9OB-kz9hOX1nEG9a0xEW9g,71
-pp_project_pkg/extra.py,sha256=K8YeaGW7-EdQUJCB7z1mFADHMWb33TEIJksLP7JmGLY,4341
-pp_project_pkg/linear_train.py,sha256=xW9v6KON3cAC3-4yP50rC6VCwv0tCeJ6h25oILWyGRw,5335
+pp_project_pkg/extra.py,sha256=cCFm5vQVbDt1Oebpe8HJI8LpjrxfELdcNrirRBLCFjo,4343
 pp_project_pkg/newsvendor.py,sha256=E6JHp0Vtmq63toKM6bO3xTAdCgwmAZzRua-w10wrc5Y,577
 pp_project_pkg/pp_tables.py,sha256=aNBP-aExfiPWTINChNLIzIIgTUrVo-z26Oq8cLTky2w,9252
+pp_project_pkg/train_loop.py,sha256=xKn5OcC4FwCc3xpq4Ig97YNzeIV9nEuwkSm2R7G3LFo,7612
 pp_project_pkg/utils.py,sha256=KmLqDW3F66lo5e4oQFNCMrUZGVtFkHbqgxjyODeeVY8,7448
-pp_project_pkg/version.py,sha256=y2szVOUBbc-5RF5EcOhA1Cm3hTm_Pg9cbwgSs1vRZCg,396
+pp_project_pkg/version.py,sha256=DdLMmoh6N6_5XXbJNqXdqh_n-1NlC66uu6gqi-if3dE,396
 pp_project_pkg/wrangling.py,sha256=g9y6mJXvtV-C1YNel_fLRjhtqpPtXcL131Mc1NdVv8s,5301
-pp_project_pkg-1.0.202307040935.data/scripts/pp_project_run.py,sha256=hNrYjtDlo7nX9pwMbM7un9R7ToKRdjVosBt3qErKtaA,1316
-pp_project_pkg-1.0.202307040935.dist-info/METADATA,sha256=PZgLnXRpWtGjMlBKdlD03axHosPAs45R8XVONbCedig,191
-pp_project_pkg-1.0.202307040935.dist-info/WHEEL,sha256=g4nMs7d-Xl9-xC9XovUrsDHGXt-FT0E17Yqo92DEfvY,92
-pp_project_pkg-1.0.202307040935.dist-info/top_level.txt,sha256=aTmpGcM2s0GVN0z4bWc23t0I3mXhHxeqKNzUWghwIRA,32
-pp_project_pkg-1.0.202307040935.dist-info/RECORD,,
+pp_project_pkg-1.0.202307041256.data/scripts/pp_project_run.py,sha256=hNrYjtDlo7nX9pwMbM7un9R7ToKRdjVosBt3qErKtaA,1316
+pp_project_pkg-1.0.202307041256.dist-info/METADATA,sha256=7PbBfXftHWgydNbJg9HulZ5EbvJWt548M7Ua0gOesi0,191
+pp_project_pkg-1.0.202307041256.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+pp_project_pkg-1.0.202307041256.dist-info/top_level.txt,sha256=aTmpGcM2s0GVN0z4bWc23t0I3mXhHxeqKNzUWghwIRA,32
+pp_project_pkg-1.0.202307041256.dist-info/RECORD,,
```

